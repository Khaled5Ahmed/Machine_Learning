{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34682b2e-80a3-4b8d-aa51-c48b69dafa6e",
   "metadata": {},
   "source": [
    "# Impotrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f702cd-d734-4e9c-bf58-934db851d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb653ff5-a9eb-4761-a888-bc5fb3d8c495",
   "metadata": {},
   "source": [
    "# Load & Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e76b2be3-647f-4a31-ae5f-9654ddba329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (32561, 8), Classes: [' <=50K' ' >50K']\n"
     ]
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "cols = ['age','workclass','fnlwgt','education','edu-num','marital','occupation',\n",
    "        'relationship','race','sex','capital-gain','capital-loss','hours','country','income']\n",
    "\n",
    "data = pd.read_csv(url, names=cols)\n",
    "cat_features = ['workclass', 'education', 'marital', 'occupation', \n",
    "                'relationship', 'race', 'sex', 'country']\n",
    "\n",
    "X = data[cat_features]\n",
    "y = data['income']\n",
    "\n",
    "print(f\"X: {X.shape}, Classes: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc43acef-f697-44b3-8394-fa9318f8c90e",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf4472c3-7e59-4e14-bf2a-e2d07e08596e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (22792, 8), Val: (4884, 8), Test: (4885, 8)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "# Convert to NumPy arrays (ensure indexing works)\n",
    "X_train = np.array(X_train)\n",
    "X_val   = np.array(X_val)\n",
    "X_test  = np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0db50-2ce6-4a07-9342-9973b1209867",
   "metadata": {},
   "source": [
    "# Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da192824-b1e2-4d76-b330-b3d211df34fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalNB:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.class_log_prior_ = None\n",
    "        self.feature_log_prob_ = None\n",
    "        self.feature_encoders = []\n",
    "        self.classes_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Encode target labels\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        y_encoded = self.label_encoder.fit_transform(y)\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "        n_classes = len(self.classes_)\n",
    "        \n",
    "        # Encode each feature separately (integer 0→N-1)\n",
    "        X_enc = np.zeros_like(X)\n",
    "        self.feature_encoders = []\n",
    "        \n",
    "        for feat in range(X.shape[1]):\n",
    "            enc = LabelEncoder()\n",
    "            X_enc[:, feat] = enc.fit_transform(X[:, feat])\n",
    "            self.feature_encoders.append(enc)\n",
    "\n",
    "        # Class priors\n",
    "        class_counts = np.bincount(y_encoded)\n",
    "        total = len(y_encoded)\n",
    "        self.class_log_prior_ = np.log((class_counts + self.alpha) / (total + self.alpha * n_classes))\n",
    "        \n",
    "        # Likelihood\n",
    "        self.feature_log_prob_ = []\n",
    "        \n",
    "        for feat in range(X_enc.shape[1]):\n",
    "            feat_probs = {}\n",
    "            vocab_size = len(np.unique(X_enc[:, feat]))\n",
    "            \n",
    "            for cls in range(n_classes):\n",
    "                cls_samples = X_enc[y_encoded == cls, feat]\n",
    "                values, counts = np.unique(cls_samples, return_counts=True)\n",
    "\n",
    "                probs = np.full(vocab_size, np.log(self.alpha / (len(cls_samples) + self.alpha * vocab_size)))\n",
    "                \n",
    "                for v, c in zip(values, counts):\n",
    "                    probs[int(v)] = np.log((c + self.alpha) / (len(cls_samples) + self.alpha * vocab_size))\n",
    "\n",
    "                feat_probs[cls] = probs\n",
    "            self.feature_log_prob_.append(feat_probs)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Apply same encoding used in training\n",
    "        X_enc = np.zeros_like(X)\n",
    "        for feat in range(X.shape[1]):\n",
    "            X_enc[:, feat] = self.feature_encoders[feat].transform(X[:, feat])\n",
    "\n",
    "        n_samples = X_enc.shape[0]\n",
    "        log_prob = np.zeros((n_samples, len(self.classes_)))\n",
    "        \n",
    "        for i, x in enumerate(X_enc):\n",
    "            for c in range(len(self.classes_)):\n",
    "                score = self.class_log_prior_[c]\n",
    "                for feat_idx, feat_val in enumerate(x):\n",
    "                    probs = self.feature_log_prob_[feat_idx][c]\n",
    "                    score += probs[int(feat_val)]\n",
    "                log_prob[i, c] = score\n",
    "        \n",
    "        return self.label_encoder.inverse_transform(np.argmax(log_prob, axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5415d734-b854-41b9-a61c-5b49d99aa4cb",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "adcbeea0-f6a2-424f-9eb8-91e7fac0a2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "α=0.1: 0.7930\n",
      "α=0.5: 0.7928\n",
      "α=1.0: 0.7926\n",
      "α=2.0: 0.7920\n",
      "α=5.0: 0.7930\n",
      "\n",
      "Best α: 0.1\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "val_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    model = CategoricalNB(alpha=alpha)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = accuracy_score(y_val, model.predict(X_val))\n",
    "    val_scores.append(score)\n",
    "    print(f\"α={alpha}: {score:.4f}\")\n",
    "\n",
    "best_alpha = alphas[np.argmax(val_scores)]\n",
    "print(f\"\\nBest α: {best_alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d255641c-7deb-4db3-9f3a-00709949cc16",
   "metadata": {},
   "source": [
    "# Final Model & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2cf84c9c-1f80-4d68-919e-02011556043f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL TEST RESULTS:\n",
      "Accuracy: 0.7969\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3077  678]\n",
      " [ 314  816]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.91      0.82      0.86      3755\n",
      "        >50K       0.55      0.72      0.62      1130\n",
      "\n",
      "    accuracy                           0.80      4885\n",
      "   macro avg       0.73      0.77      0.74      4885\n",
      "weighted avg       0.82      0.80      0.81      4885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train on train+val\n",
    "X_train_final = np.vstack([X_train, X_val])\n",
    "y_train_final = np.hstack([y_train, y_val])\n",
    "\n",
    "final_model = CategoricalNB(alpha=best_alpha)\n",
    "final_model.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Test results\n",
    "y_pred = final_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nFINAL TEST RESULTS:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c13ad9-56f6-4086-8c3f-277811576e99",
   "metadata": {},
   "source": [
    "# Analysis Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "df453507-b41a-45fd-8840-0737a7b1a2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features ['workclass', 'education', 'marital']: Accuracy = 0.8184\n",
      "Features ['occupation', 'relationship', 'race', 'sex']: Accuracy = 0.7895\n",
      "Features ['workclass', 'education', 'marital', 'occupation', 'relationship', 'race', 'sex', 'country']: Accuracy = 0.7930\n"
     ]
    }
   ],
   "source": [
    "feature_sets = [\n",
    "    ['workclass', 'education', 'marital'],  # small group of features\n",
    "    ['occupation', 'relationship', 'race', 'sex'],  # large group of features\n",
    "    cat_features  # all features\n",
    "]\n",
    "\n",
    "for features in feature_sets:\n",
    "    X_train_subset = X_train[:, [cat_features.index(f) for f in features]]\n",
    "    X_val_subset = X_val[:, [cat_features.index(f) for f in features]]\n",
    "    \n",
    "    model = CategoricalNB(alpha=best_alpha)\n",
    "    model.fit(X_train_subset, y_train)\n",
    "    score = accuracy_score(y_val, model.predict(X_val_subset))\n",
    "    print(f\"Features {features}: Accuracy = {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b995d-84a2-4f95-8bd8-720ab77b0fe8",
   "metadata": {},
   "source": [
    "#  Performance Comparison: Compare with sklearn's MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c4125c75-4e9d-4b3f-afe4-13f4a734cf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Test Accuracy: 0.7548\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3221  534]\n",
      " [ 664  466]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84      3755\n",
      "           1       0.47      0.41      0.44      1130\n",
      "\n",
      "    accuracy                           0.75      4885\n",
      "   macro avg       0.65      0.64      0.64      4885\n",
      "weighted avg       0.75      0.75      0.75      4885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Encode categorical features \n",
    "X_train_enc = np.column_stack([LabelEncoder().fit_transform(X_train[:, i]) for i in range(X_train.shape[1])])\n",
    "X_val_enc   = np.column_stack([LabelEncoder().fit_transform(X_val[:, i]) for i in range(X_val.shape[1])])\n",
    "X_test_enc  = np.column_stack([LabelEncoder().fit_transform(X_test[:, i]) for i in range(X_test.shape[1])])\n",
    "\n",
    "# Encode target labels\n",
    "le_y = LabelEncoder()\n",
    "y_train_enc = le_y.fit_transform(y_train)\n",
    "y_val_enc   = le_y.transform(y_val)   \n",
    "y_test_enc  = le_y.transform(y_test)   \n",
    "\n",
    "# Train MultinomialNB on train + val\n",
    "X_train_final = np.vstack([X_train_enc, X_val_enc])\n",
    "y_train_final = np.hstack([y_train_enc, y_val_enc])\n",
    "\n",
    "sk_model = MultinomialNB(alpha=best_alpha)\n",
    "sk_model.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Test\n",
    "y_pred = sk_model.predict(X_test_enc)\n",
    "accuracy = accuracy_score(y_test_enc, y_pred)\n",
    "\n",
    "print(f\"MultinomialNB Test Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test_enc, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_enc, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
